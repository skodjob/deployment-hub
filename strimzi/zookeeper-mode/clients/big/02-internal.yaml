---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: big-internal-producer
  name: big-internal-producer
spec:
  replicas: 3
  selector:
    matchLabels:
      app: big-internal-producer
  template:
    metadata:
      labels:
        app: big-internal-producer
    spec:
      serviceAccountName: clients-sa
      containers:
        - name: big-internal-producer
          image: quay.io/strimzi-test-clients/test-clients:latest-kafka-3.5.0
          imagePullPolicy: Always
          resources:
            requests:
              memory: 50Mi
              cpu: 50m
            limits:
              memory: 350Mi
              cpu: 350m
          env:
            - name: CA_CRT
              value: ${secrets:strimzi-kafka/anubis-cluster-ca-cert:ca.crt}
            - name: USER_CRT
              value: ${secrets:strimzi-kafka/kafka-internal-producer:user.crt}
            - name: USER_KEY
              value: ${secrets:strimzi-kafka/kafka-internal-producer:user.key}
            - name: BOOTSTRAP_SERVERS
              value: anubis-kafka-bootstrap.strimzi-kafka.svc:9093
            - name: TOPIC
              value: big-internal-data
            - name: DELAY_MS
              value: "1000"
            - name: MESSAGE
              value: |
                I am sending a little big bigger messages, no random ones, but a longer than hello world, wdyt?
                I started to write a story about it, but it seems the data are not enough to fill all the pages that book requires.
                Another line! What a message, right? I think it is enough!
                I am sending a little big bigger messages, no random ones, but a longer than hello world, wdyt?
                I started to write a story about it, but it seems the data are not enough to fill all the pages that book requires.
                Another line! What a message, right? I think it is enough!
                I am sending a little big bigger messages, no random ones, but a longer than hello world, wdyt?
                I started to write a story about it, but it seems the data are not enough to fill all the pages that book requires.
                Another line! What a message, right? I think it is enough! Demo time!
            - name: LOG_LEVEL
              value: "INFO"
            - name: MESSAGE_COUNT
              value: "100000000"
            - name: PRODUCER_ACKS
              value: all
            - name: ADDITIONAL_CONFIG
            - name: BLOCKING_PRODUCER
              value: "true"
            - name: CLIENT_TYPE
              value: KafkaProducer
      tolerations:
        - key: "nodetype"
          operator: "Equal"
          value: "connect"
          effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nodetype
                    operator: In
                    values:
                      - connect

---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: big-internal-streams
  name: big-internal-streams
spec:
  replicas: 3
  selector:
    matchLabels:
      app: big-internal-streams
  template:
    metadata:
      labels:
        app: big-internal-streams
    spec:
      serviceAccountName: clients-sa
      containers:
        - name: big-internal-streams
          image: quay.io/strimzi-test-clients/test-clients:latest-kafka-3.5.0
          imagePullPolicy: Always
          resources:
            requests:
              memory: 50Mi
              cpu: 50m
            limits:
              memory: 400Mi
              cpu: 250m
          env:
            - name: CA_CRT
              value: ${secrets:strimzi-kafka/anubis-cluster-ca-cert:ca.crt}
            - name: USER_CRT
              value: ${secrets:strimzi-kafka/kafka-internal-streams:user.crt}
            - name: USER_KEY
              value: ${secrets:strimzi-kafka/kafka-internal-streams:user.key}
            - name: BOOTSTRAP_SERVERS
              value: anubis-kafka-bootstrap.strimzi-kafka.svc:9093
            - name: APPLICATION_ID
              value: big-internal-data-streams
            - name: SOURCE_TOPIC
              value: big-internal-data
            - name: TARGET_TOPIC
              value: big-internal-data-reversed
            - name: LOG_LEVEL
              value: "INFO"
            - name: CLIENT_TYPE
              value: KafkaStreams
      tolerations:
        - key: "nodetype"
          operator: "Equal"
          value: "connect"
          effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nodetype
                    operator: In
                    values:
                      - connect

---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: big-internal-consumer
  name: big-internal-consumer
spec:
  replicas: 4
  selector:
    matchLabels:
      app: big-internal-consumer
  template:
    metadata:
      labels:
        app: big-internal-consumer
    spec:
      serviceAccountName: clients-sa
      containers:
        - name: big-internal-consumer
          image: quay.io/strimzi-test-clients/test-clients:latest-kafka-3.5.0
          imagePullPolicy: Always
          resources:
            requests:
              memory: 50Mi
              cpu: 50m
            limits:
              memory: 250Mi
              cpu: 250m
          env:
            - name: CA_CRT
              value: ${secrets:strimzi-kafka/anubis-cluster-ca-cert:ca.crt}
            - name: USER_CRT
              value: ${secrets:strimzi-kafka/kafka-internal-consumer:user.crt}
            - name: USER_KEY
              value: ${secrets:strimzi-kafka/kafka-internal-consumer:user.key}
            - name: BOOTSTRAP_SERVERS
              value: anubis-kafka-bootstrap.strimzi-kafka.svc:9093
            - name: TOPIC
              value: big-internal-data-reversed
            - name: GROUP_ID
              value: big-internal-data-consumer
            - name: LOG_LEVEL
              value: "INFO"
            - name: MESSAGE_COUNT
              value: "100000000"
            - name: CLIENT_TYPE
              value: KafkaConsumer
      tolerations:
        - key: "nodetype"
          operator: "Equal"
          value: "connect"
          effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nodetype
                    operator: In
                    values:
                      - connect
